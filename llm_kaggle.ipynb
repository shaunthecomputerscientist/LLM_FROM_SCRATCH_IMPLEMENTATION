{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 泅 Kaggle-Ready GPT-2 Training Notebook\n",
                "\n",
                "**This notebook automatically downloads all code from GitHub!**\n",
                "\n",
                "Just upload this `.ipynb` file to Kaggle and run all cells."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 1: SETUP - AUTO-CLONE FROM GITHUB\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Check if we're on Kaggle or Colab\n",
                "is_kaggle = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
                "is_colab = 'COLAB_GPU' in os.environ\n",
                "\n",
                "if is_kaggle or is_colab:\n",
                "    print(\"沐 Running on cloud platform - cloning repository...\")\n",
                "    \n",
                "    # Clone the repository\n",
                "    !git clone https://github.com/shaunthecomputerscientist/LLM_FROM_SCRATCH_IMPLEMENTATION.git\n",
                "    \n",
                "    # Change to repo directory\n",
                "    os.chdir('LLM_FROM_SCRATCH_IMPLEMENTATION')\n",
                "    \n",
                "    # Add to Python path\n",
                "    sys.path.insert(0, os.getcwd())\n",
                "    \n",
                "    # Install requirements\n",
                "    !pip install -q -r requirements.txt\n",
                "    \n",
                "    print(\"笨 Repository cloned and ready!\")\n",
                "    print(f\"沒 Current directory: {os.getcwd()}\")\n",
                "    \n",
                "else:\n",
                "    print(\"汳ｻ Running locally - using local files\")\n",
                "    from pathlib import Path\n",
                "    sys.path.insert(0, str(Path.cwd()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 2: IMPORTS\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "import torch\n",
                "import tiktoken\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from llm_from_scratch.GPT2Model.gpt2 import GPTModel\n",
                "from llm_from_scratch.Dataset.loader import create_dataloader_v1\n",
                "from llm_from_scratch.Trainer.trainer import (\n",
                "    train_model_simple,\n",
                "    generate_text_simple\n",
                ")\n",
                "\n",
                "print(f\"笨 PyTorch: {torch.__version__}\")\n",
                "print(f\"笨 Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 3: CONFIGURATION\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "\n",
                "cfg = {\n",
                "    # Model architecture (smaller for Kaggle)\n",
                "    \"vocab_size\": 50257,\n",
                "    \"context_length\": 256,     # Reduced for speed\n",
                "    \"emb_dim\": 768,\n",
                "    \"n_heads\": 12,\n",
                "    \"n_layers\": 6,             # Reduced from 12\n",
                "    \"drop_rate\": 0.1,\n",
                "    \"qkv_bias\": False,\n",
                "    \"use_flash\": torch.cuda.is_available(),  # Auto-detect\n",
                "    \n",
                "    # Dataloader\n",
                "    \"batch_size\": 4,\n",
                "    \"stride\": 64,\n",
                "    \"train_ratio\": 0.90,\n",
                "}\n",
                "\n",
                "print(\"沒 Configuration:\")\n",
                "for k, v in cfg.items():\n",
                "    print(f\"   {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 4: LOAD DATASET\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "from datasets import load_dataset\n",
                "\n",
                "# Download small sample from HuggingFace\n",
                "print(\"沒･ Downloading dataset...\")\n",
                "dataset = load_dataset(\n",
                "    \"HuggingFaceFW/fineweb-edu\",\n",
                "    name=\"sample-10BT\",\n",
                "    split=\"train\",\n",
                "    streaming=True\n",
                ")\n",
                "\n",
                "# Take first 50 documents (~5MB text)\n",
                "raw_text = \"\"\n",
                "for i, doc in enumerate(dataset):\n",
                "    if i >= 50:\n",
                "        break\n",
                "    raw_text += doc['text'] + \"\\n\\n\"\n",
                "\n",
                "print(f\"笨 Dataset: {len(raw_text):,} characters\")\n",
                "\n",
                "# Split and create loaders\n",
                "split_idx = int(cfg[\"train_ratio\"] * len(raw_text))\n",
                "train_data = raw_text[:split_idx]\n",
                "val_data = raw_text[split_idx:]\n",
                "\n",
                "train_loader = create_dataloader_v1(\n",
                "    train_data,\n",
                "    batch_size=cfg[\"batch_size\"],\n",
                "    max_length=cfg[\"context_length\"],\n",
                "    stride=cfg[\"stride\"]\n",
                ")\n",
                "\n",
                "val_loader = create_dataloader_v1(\n",
                "    val_data,\n",
                "    batch_size=cfg[\"batch_size\"],\n",
                "    max_length=cfg[\"context_length\"],\n",
                "    stride=cfg[\"stride\"]\n",
                ")\n",
                "\n",
                "print(f\"沒 Train batches: {len(train_loader)}\")\n",
                "print(f\"沒 Val batches: {len(val_loader)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 5: INITIALIZE MODEL\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "model = GPTModel(cfg).to(device)\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
                "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"沐｢ Total parameters: {total_params:,}\")\n",
                "print(f\"汳ｾ Model size: {total_params * 4 / 1024**2:.1f} MB (FP32)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 6: TRAIN MODEL\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "print(\"泅 Starting training...\\n\")\n",
                "\n",
                "train_losses, val_losses, tokens_seen = train_model_simple(\n",
                "    model=model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=val_loader,\n",
                "    optimizer=optimizer,\n",
                "    device=device,\n",
                "    num_epochs=5,\n",
                "    eval_freq=10,\n",
                "    eval_iter=5,\n",
                "    start_context=\"Every effort moves\",\n",
                "    tokenizer=tokenizer,\n",
                "    memory_efficient=torch.cuda.is_available(),\n",
                "    accumulation_steps=4\n",
                ")\n",
                "\n",
                "print(\"\\n笨 Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 7: PLOT TRAINING CURVES\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "plt.figure(figsize=(12, 4))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(train_losses, label='Train Loss', color='blue')\n",
                "plt.plot(val_losses, label='Val Loss', color='orange')\n",
                "plt.xlabel('Evaluation Step')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Training Progress')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(tokens_seen, train_losses, color='blue')\n",
                "plt.xlabel('Tokens Seen')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Loss vs Tokens')\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 8: GENERATE TEXT\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "model.eval()\n",
                "\n",
                "prompts = [\n",
                "    \"Every effort moves\",\n",
                "    \"The artist pondered\",\n",
                "    \"In the beginning\"\n",
                "]\n",
                "\n",
                "print(\"沁ｨ Generated Text:\\n\" + \"=\"*60)\n",
                "\n",
                "for prompt in prompts:\n",
                "    encoded = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
                "    \n",
                "    output = generate_text_simple(\n",
                "        model=model,\n",
                "        idx=encoded,\n",
                "        max_new_tokens=30,\n",
                "        context_size=cfg[\"context_length\"],\n",
                "        temperature=0.7,\n",
                "        top_k=10\n",
                "    )\n",
                "    \n",
                "    generated = tokenizer.decode(output.squeeze(0).tolist())\n",
                "    print(f\"\\n沒 {generated}\")\n",
                "    print(\"-\" * 60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# CELL 9: SAVE MODEL\n",
                "# 笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊申n",
                "# Save checkpoint\n",
                "checkpoint = {\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'optimizer_state_dict': optimizer.state_dict(),\n",
                "    'config': cfg,\n",
                "    'train_losses': train_losses,\n",
                "    'val_losses': val_losses,\n",
                "    'tokens_seen': tokens_seen\n",
                "}\n",
                "\n",
                "torch.save(checkpoint, 'gpt2_checkpoint.pt')\n",
                "print(\"笨 Full checkpoint saved: gpt2_checkpoint.pt\")\n",
                "\n",
                "# Save just weights (smaller file)\n",
                "torch.save(model.state_dict(), 'gpt2_weights.pt')\n",
                "print(\"笨 Weights saved: gpt2_weights.pt\")\n",
                "\n",
                "print(\"\\n沒･ Download these files from Kaggle output folder!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}